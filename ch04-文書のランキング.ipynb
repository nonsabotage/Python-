{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "検索システムを構築することを考えたとき，ある検索語に対して，複数の文書がヒットすることがある．\n",
    "\n",
    "このような状況ではランキングが必要となる．ランキングは検索語を文書と見なして，文書と文書の類似度から求める．\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 文書のランキング\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 特徴語集合の類似性\n",
    "\n",
    "特徴語の類似性から文書のランキングを求める．\n",
    "一般には次の三つがある. \n",
    "\n",
    "- Jaccard\n",
    "- Dice\n",
    "- Simposon\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import importlib\n",
    "from  janome.tokenizer import Tokenizer\n",
    "import re\n",
    "import pathlib\n",
    "from py import my_module as mm\n",
    "from pprint import pprint\n",
    "from gensim import corpora, models\n",
    "importlib.reload(mm)\n",
    "\n",
    "from janome.tokenizer import Tokenizer\n",
    "from janome.analyzer import Analyzer\n",
    "from janome.tokenfilter import ExtractAttributeFilter\n",
    "from janome.tokenfilter import POSStopFilter\n",
    "from janome.tokenfilter import POSKeepFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fmt = \"irpb-files/data/ch04/{:d}.txt\"\n",
    "book_texts = [mm.get_string_from_file(data_fmt.format(i)) for i in range(10)]\n",
    "\n",
    "tfidf_model, dic, book_weights = mm.get_tfidfmodel_and_weights(book_texts)\n",
    "\n",
    "keyword_lists = [[x0 for x0, *_ in w[:10]] for w in book_weights]\n",
    "\n",
    "results = [(x, mm.jaccard(keyword_lists[9], keyword_lists[x])) for x in range(9)]\n",
    "\n",
    "results.sort(key = lambda x: x[1], reverse = True)\n",
    "\n",
    "with open(\"irpb-files/data/ch04/book-titles.txt\", encoding = \"UTF-8\") as f:\n",
    "    titles = f.read().strip().split(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ブラックホールと時空の方程式 0.1111\n逆数学 0.1111\n64の事例からわかる金属腐食の対策 0.0526\nCoq/SSReflect/MathCompによる定理証明 0.0526\n基礎からわかる高分子材料 0.0000\nゼロからはじめるVisual_C#入門 0.0000\n実践_地域・まちづくりワーク 0.0000\n応用数学問題集 0.0000\n生態系生態学(第2版) 0.0000\n"
     ]
    }
   ],
   "source": [
    "for x in range(9):\n",
    "    print(\"%s %.4f\" % (titles[results[x][0]], results[x][1]))"
   ]
  },
  {
   "source": [
    "## ベクトル空間モデル\n",
    "\n",
    "TF・IDFは特徴語としての性能を示すものであった．\n",
    "\n",
    "ここではTF・IDFを語が文書を特徴付に寄与してい度合いと考え，その分布が文書の内容を表していると考える．\n",
    "\n",
    "これは文章を特徴語のTF・IDFで示されるベクトルだと考えることになる．これをベクトル空間モデルという. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dic[0] = 団子\ndic[1] = 花\ndic[2] = あんこ\ndic[3] = みたらし\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "texts = [\"花より団子．とにかく団子\", \"みたらしよりあんこ\"]\n",
    "\n",
    "words = [mm.get_words(text, keep_pos = [\"名詞\"]) for text in texts]\n",
    "dic = corpora.Dictionary(words)\n",
    "\n",
    "for i in range(len(dic)):\n",
    "    print(\"dic[%d] = %s\" % (i, dic[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "wegihts =  [(0, 0.8944), (1, 0.4472)]\n"
     ]
    }
   ],
   "source": [
    "bows = [dic.doc2bow(w) for w in words]\n",
    "tfidf = models.TfidfModel(bows)\n",
    "weights = tfidf[bows[0]]\n",
    "weights = [(i, round(j, 4)) for i, j in weights]\n",
    "print(\"wegihts = \", weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "wegihts =  [(0, 2), (1, 1)]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dic[逆数学] = 0.420418\ndic[ブラックホールと時空の方程式] = 0.27373135\ndic[Coq/SSReflect/MathCompによる定理証明] = 0.17463519\ndic[応用数学問題集] = 0.11947917\ndic[64の事例からわかる金属腐食の対策] = 0.06601203\ndic[実践_地域・まちづくりワーク] = 0.038086623\ndic[ゼロからはじめるVisual_C#入門] = 0.02615247\ndic[生態系生態学(第2版)] = 0.025868826\ndic[基礎からわかる高分子材料] = 0.024284441\n"
     ]
    }
   ],
   "source": [
    "data_fmt = \"irpb-files/data/ch04/{:d}.txt\"\n",
    "book_texts = [mm.get_string_from_file(data_fmt.format(i)) for i in range(10)]\n",
    "\n",
    "titles = mm.get_list_from_file(\"irpb-files/data/ch04/book-titles.txt\")\n",
    "\n",
    "result = mm.vsm_search(book_texts[:-1], book_texts[9])\n",
    "\n",
    "\n",
    "for x in range(9):\n",
    "    print(\"dic[%s] = %s\" % (titles[result[x][0]], result[x][1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}